{
 "metadata": {
  "name": "",
  "signature": "sha256:ea40ac00126b9f05cac940fd608e17873ca793667c30020377976b3dbc42f8cf"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Before running everything, make sure to:\n",
      "1. Find out how big the files are going to be for one quarter\n",
      "2. Put in pauses at strategic points\n",
      "3. keep track of how many files have been traversed so we can pick up where we left off\n",
      "4. figure out if it's ok to write to MongoDB on the shared drive"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Import Libraries\n",
      "from ftplib import FTP\n",
      "from time import time, sleep\n",
      "from datetime import datetime\n",
      "import pickle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = \"06:00:00\"\n",
      "now = datetime.now().time()\n",
      "stop_time=datetime.strptime(\"06:00:00\",\"%H:%M:%S\").time()\n",
      "print dt\n",
      "print now\n",
      "print dt < now\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "06:00:00\n",
        "15:55:13.909000\n",
        "True\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Connect to ftp and login\n",
      "#def ftp_login(host, username, pword):\n",
      "#return ftp\n",
      "ftp = FTP(\"ftp.sec.gov\")\n",
      "ftp.login()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 160,
       "text": [
        "'230-Anonymous access granted, restrictions apply\\n \\n Please read the file README.txt\\n230    it was last modified on Tue Aug 15 14:29:31 2000 - 5180 days ago'"
       ]
      }
     ],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Get list of directories (assumes a certain structure)\n",
      "def get_dir_list(ftp_class):\n",
      "    ls = []\n",
      "    dir_list = []\n",
      "    ftp_class.retrlines('MLSD', ls.append)\n",
      "    for entry in ls:\n",
      "        split = entry.split(\";\")\n",
      "        if split[2] == \"type=dir\":\n",
      "            dir_list.append(split[-1][1:])\n",
      "\n",
      "    return dir_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dir_list = get_dir_list(ftp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1993\n",
        "1994\n",
        "1995\n",
        "1996\n",
        "1997\n",
        "1998\n",
        "1999\n",
        "2000\n",
        "2001\n",
        "2002\n",
        "2003\n",
        "2004\n",
        "2005\n",
        "2006\n",
        "2007\n",
        "2008\n",
        "2009\n",
        "2010\n",
        "2011\n",
        "2012\n",
        "2013\n",
        "2014\n"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Download file to local directory; use switch to determine naming conventions\n",
      "#Returns the local filepath to be fed into the next function***Test this\n",
      "def download_local_file(filename, destination, switch, ftp_class):\n",
      "    \n",
      "    #If we want to append part of the directory name to the file\n",
      "    if switch == 2:\n",
      "        #Get the last two elements of the filepath\n",
      "        filepath = ftp_class.pwd()\n",
      "        \n",
      "        split = filepath.split('/')\n",
      "        extension = \"_\".join(split[-2:])\n",
      "\n",
      "        local_file = open(destination + extension + \"_\" + filename, 'w')\n",
      "        ftp_class.retrbinary(\"RETR \" + filename, local_file.write)\n",
      "        local_file.close()\n",
      "        \n",
      "        return destination + extension + \"_\" + filename\n",
      "    \n",
      "    elif switch == 1:\n",
      "\n",
      "        #local_file = open(destination + extension + \"_\" + filename, 'w')\n",
      "        binary_data = []\n",
      "        ftp_class.retrbinary(\"RETR \" + filename, binary_data.append)\n",
      "        #local_file.close()\n",
      "        \n",
      "        return binary_data\n",
      "    \n",
      "    elif switch == 3:\n",
      "                \n",
      "        split = filename.split('/')\n",
      "        name = destination + split[-2] + \"_\" + split[-1]\n",
      "\n",
      "        local_file = open(name, 'w')\n",
      "        ftp_class.retrbinary(\"RETR \" + filename, local_file.write)\n",
      "        local_file.close()\n",
      "        \n",
      "        return name\n",
      "    #if not...\n",
      "    else:\n",
      "        \n",
      "        local_file = open(destination + filename, 'w')\n",
      "        ftp_class.retrbinary(\"RETR \" + filename, local_file.write)\n",
      "        local_file.close()\n",
      "        \n",
      "        return destination + extension + \"_\" + filename"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "local_path = download_local_file(\"0001110550-06-000003.txt\", \"C:\\\\Users\\\\zacharybeaver\\\\Documents\\\\Github_stuffs\\\\web_scraping\\\\edgar\\\\\", 1, ftp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 162
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ftp.cwd(\"/edgar/data/1114831/\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 161,
       "text": [
        "'250 CWD command successful'"
       ]
      }
     ],
     "prompt_number": 161
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Read index and return list of file paths and metadata\n",
      "def get_file_paths(indexed_file):\n",
      "    \n",
      "    with open(indexed_file, \"r\") as index_file:\n",
      "        index_list = list(index_file)\n",
      "    \n",
      "    #Find indices for splitting fields (since their fixed-width)\n",
      "    index_list = index_list[10:]\n",
      "    company_name_i = 62\n",
      "    form_type_i = 74\n",
      "    cik_i = 86\n",
      "    date_filed_i = 98\n",
      "    file_name_i = len(index_list[0])\n",
      "\n",
      "    cleaned_indices = []\n",
      "    file_paths = []\n",
      "    \n",
      "    for index in index_list:\n",
      "        metadata = []\n",
      "        metadata.append(index[:company_name_i].rstrip())\n",
      "        metadata.append(index[company_name_i:form_type_i].rstrip())\n",
      "        metadata.append(index[form_type_i:cik_i].rstrip())\n",
      "        metadata.append(index[cik_i:date_filed_i].rstrip())\n",
      "        file_path = index[date_filed_i:file_name_i].rstrip()\n",
      "        metadata.append(file_path)\n",
      "        file_paths.append(\"/\" + file_path)\n",
      "        cleaned_indices.append(metadata)\n",
      "        \n",
      "    return file_paths, cleaned_indices"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Try to put it all together\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "paths, metadata = get_file_paths(\"C:\\\\Users\\\\zacharybeaver\\\\Documents\\\\Github_stuffs\\\\web_scraping\\\\edgar\\\\2006_QTR1_company.idx\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 153
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Insert the file and metadata into Mongo DB\n",
      "#def download_filepath_file(filepath, ftp_class)\n",
      "#return"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Testing a single case"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Connect to ftp and login\n",
      "#def ftp_login(host, username, pword):\n",
      "#return ftp\n",
      "ftp = FTP(\"ftp.sec.gov\")\n",
      "ftp.login()\n",
      "\n",
      "#Running through the functions for getting a few documents\n",
      "#navigate to the index section\n",
      "base = \"/edgar/full-index/\"\n",
      "ftp.cwd(base)\n",
      "\n",
      "#Get a list of all directories (\"years\") in that section\n",
      "dir_list = get_dir_list(ftp)\n",
      "print dir_list\n",
      "\n",
      "#Change directories to one of the directories in the list\n",
      "ftp.cwd(dir_list[4])\n",
      "print ftp.pwd()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 167,
       "text": [
        "'230-Anonymous access granted, restrictions apply\\n \\n Please read the file README.txt\\n230    it was last modified on Tue Aug 15 14:29:31 2000 - 5180 days ago'"
       ]
      }
     ],
     "prompt_number": 167
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Running through the functions for getting a few documents\n",
      "#navigate to the index section\n",
      "ftp = FTP(\"ftp.sec.gov\")\n",
      "ftp.login()\n",
      "\n",
      "time1 = time()\n",
      "\n",
      "base = \"/edgar/full-index/\"\n",
      "ftp.cwd(base)\n",
      "\n",
      "#Get a list of all directories (\"years\") in that section\n",
      "dir_list = get_dir_list(ftp)\n",
      "\n",
      "#Change directories to one of the directories in the list\n",
      "ftp.cwd(dir_list[4])\n",
      "\n",
      "#Get the directories (quarters in the new directory)\n",
      "quarter_list = get_dir_list(ftp)\n",
      "\n",
      "#Change directories\n",
      "ftp.cwd(quarter_list[1])\n",
      "\n",
      "#Get the index file\n",
      "local_filepath = download_local_file(\"company.idx\", \"C:\\\\Users\\\\zacharybeaver\\\\Documents\\\\Github_stuffs\\\\web_scraping\\\\edgar\\\\\", 2, ftp)\n",
      "\n",
      "#Get the filepaths and metadata\n",
      "paths, metadata = get_file_paths(local_filepath)\n",
      "\n",
      "time2 = time()\n",
      "\n",
      "#download the file from a returned filepath\n",
      "document = download_local_file(paths[0], \"\", 1, ftp)\n",
      "time3 = time()\n",
      "print \"Time to download index:\", time2 - time1\n",
      "print \"Time to donwload document:\", time3 - time2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ftp = FTP(\"ftp.sec.gov\")\n",
      "ftp.login()\n",
      "new_paths = []\n",
      "bad = []\n",
      "\n",
      "time1 = time()\n",
      "for i in range(1000, 2000):\n",
      "    try:\n",
      "        new_paths.append(download_local_file(paths[i],\"C:\\\\Users\\\\zacharybeaver\\\\Documents\\\\Github_stuffs\\\\web_scraping\\\\edgar\\\\tester\\\\\", 3, ftp))\n",
      "    except:\n",
      "        bad.append(paths[i])\n",
      "    \n",
      "    #if i % 100 == 0:\n",
      "        #sleep(5)\n",
      "\n",
      "time2 = time()\n",
      "print time2 - time1, \"for 1000 documents\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "194.453999996 for 1000 documents\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#This function compares whether it is 6 am yet or not\n",
      "def after_six_am():\n",
      "    now = datetime.now().time()\n",
      "    stop_time=datetime.strptime(\"06:00:00\",\"%H:%M:%S\").time()\n",
      "    nine_pm = datetime.strptime(\"21:00:00\",\"%H:%M:%S\").time()\n",
      "    return now > stop_time and now < nine_pm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"C:\\\\Users\\\\zacharybeaver\\\\Documents\\\\Edgar\\\\all_indices.txt\", \"r\") as indices:\n",
      "    ###need to fix this to pick up where left off\n",
      "    indices_list = list(indices)\n",
      "\n",
      "with open(\"C:\\\\Users\\\\zacharybeaver\\\\Documents\\\\Edgar\\\\indexes_left.pickle\", \"wb\") as f:\n",
      "    for i in range(len(indices_list)):\n",
      "        indices_list[i] = indices_list[i][:-1]\n",
      "    pickle.dump(indices_list, f)\n",
      "\n",
      "with open(\"C:\\\\Users\\\\zacharybeaver\\\\Documents\\\\Edgar\\\\all_metadata.txt\", \"r\") as metadata:\n",
      "    ###need to fix this to pick up where left off\n",
      "    metadata_list = list(metadata)\n",
      "\n",
      "with open(\"C:\\\\Users\\\\zacharybeaver\\\\Documents\\\\Edgar\\\\metadata_left.pickle\", \"wb\") as f:\n",
      "    for i in range(len(metadata_list)):\n",
      "        metadata_list[i] = metadata_list[i][:-1]\n",
      "    pickle.dump(metadata_list, f)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Load pickle files and start the process\n",
      "index_pickle_file = \"C:\\\\Users\\\\zacharybeaver\\\\Documents\\\\Github_stuffs\\\\web_scraping\\\\edgar\\\\indexes_left.pickle\"\n",
      "metadata_pickle_file = \"C:\\\\Users\\\\zacharybeaver\\\\Documents\\\\Github_stuffs\\\\web_scraping\\\\edgar\\\\metadata_left.pickle\"\n",
      "indices_list = pickle.load(open(index_pickle_file, \"rb\"))\n",
      "metadata_list = pickle.load(open(metadata_pickle_file, \"rb\"))\n",
      "print indices_list[5]\n",
      "print metadata_list[5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/edgar/data/1062045/0000950123-98-005298.txt\n",
        "1224 CORP|SC 14D9|1062045|1998-05-19\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Define paths as variables so they can be easily changed later\n",
      "####Still need to put in something to catch any disconnects and re-login#####\n",
      "metadata_output_file = \"C:\\\\Users\\\\zacharybeaver\\\\Documents\\\\Github_stuffs\\\\web_scraping\\\\edgar\\\\metadata.txt\"\n",
      "bad_list_output_file = \"C:\\\\Users\\\\zacharybeaver\\\\Documents\\\\Github_stuffs\\\\web_scraping\\\\edgar\\\\bad_list.txt\"\n",
      "dl_doc_destination = \"C:\\\\Users\\\\zacharybeaver\\\\Documents\\\\Github_stuffs\\\\web_scraping\\\\edgar\\\\documents\\\\\"\n",
      "\n",
      "#Login function\n",
      "def login():\n",
      "    try:\n",
      "        ftp = FTP(\"ftp.sec.gov\")\n",
      "        ftp.login()\n",
      "        ftp.pwd()\n",
      "        \n",
      "    except:\n",
      "        if after_six_am():\n",
      "            pass\n",
      "        else:\n",
      "            sleep(20)\n",
      "            login()\n",
      "            \n",
      "login()\n",
      "        \n",
      "\n",
      "#Open a metadata file to begin collecting all the metadata\n",
      "meta_file = open(metadata_output_file, \"wb\")\n",
      "bad_list = open(bad_list_output_file, \"wb\")\n",
      "\n",
      "#Loop through each item in the index list\n",
      "for i in range(len(indices_list)):\n",
      "    try:\n",
      "        \n",
      "        #Get the document of interest\n",
      "        meta_file.write(metadata_list[i] + \"|\" + download_local_file(indices_list[i], dl_doc_destination, 3, ftp) + \"\\n\")\n",
      "        \n",
      "    except gaierror:\n",
      "        login()\n",
      "        bad_list.write(indices_list[i] + \"\\n\")\n",
      "        \n",
      "    except:\n",
      "        bad_list.write(indices_list[i] + \"\\n\")\n",
      "    \n",
      "    #Check after every thousand files to see if we're within our time limits\n",
      "    if i % 1000 == 0:\n",
      "        if after_six_am():\n",
      "            \n",
      "            with open(index_pickle_file, \"wb\") as f:\n",
      "                #Only dump all the indices that haven't been traversed\n",
      "                pickle.dump(indices_list[i + 1:], f)\n",
      "                \n",
      "            with open(metadata_pickle_file, \"wb\") as f:\n",
      "                #only dump indices that haven't been traversed\n",
      "                pickle.dump(metadata_list[i + 1:], f)\n",
      "            \n",
      "            #Break the loop\n",
      "            break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###To add appended text...needed for adding to metadata file###\n",
      "with open(\"test.txt\", \"a\") as myfile:\n",
      "    myfile.write(\"appended text\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Run through all the index files and download them to our directory\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#insert pause between downloads\n",
      "#def insert_pause():\n",
      "#return"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Putting it all together"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}